<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.3.1"/>
<title>RLPy: Agent Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
  $(window).load(resizeHeight);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { searchBox.OnSelectItem(0); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="ACL_logo.png"/></td>
  <td style="padding-left: 0.5em;">
   <div id="projectname">RLPy
   &#160;<span id="projectnumber">Version 1.0</span>
   </div>
   <div id="projectbrief">The Reinforcement Learning Library for Education and Research</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.3.1 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="install_8txt.html#the_install_page"><span>Installation</span></a></li>
      <li><a href="_i_shouldrun_8py.html"><span>Tutorial</span></a></li>
      <li><a href="_f_a_q_8txt.html"><span>Frequently&#160;Asked&#160;Questions&#160;(FAQ)</span></a></li>
      <li class="current"><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="_code.html"><span>Code</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="annotated.html"><span>Class&#160;List</span></a></li>
      <li><a href="classes.html"><span>Class&#160;Index</span></a></li>
    </ul>
  </div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('class_agents_1_1_agent_1_1_agent.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Classes</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Namespaces</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(3)"><span class="SelectionMark">&#160;</span>Functions</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(4)"><span class="SelectionMark">&#160;</span>Variables</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(5)"><span class="SelectionMark">&#160;</span>Pages</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-attribs">Public Attributes</a> &#124;
<a href="#pub-static-attribs">Static Public Attributes</a> &#124;
<a href="class_agents_1_1_agent_1_1_agent-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">Agent Class Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p>The <a class="el" href="class_agents_1_1_agent_1_1_agent.html" title="The Agent receives observations from the Domain and performs actions to obtain some goal...">Agent</a> receives observations from the <a class="el" href="class_domains_1_1_domain_1_1_domain.html">Domain</a> and performs actions to obtain some goal.  
 <a href="class_agents_1_1_agent_1_1_agent.html#details">More...</a></p>
<div class="dynheader">
Inheritance diagram for Agent:</div>
<div class="dyncontent">
 <div class="center">
  <img src="class_agents_1_1_agent_1_1_agent.png" usemap="#Agent_map" alt=""/>
  <map id="Agent_map" name="Agent_map">
<area href="class_agents_1_1_greedy___g_q_1_1_greedy___g_q.html" alt="Greedy_GQ" shape="rect" coords="0,112,106,136"/>
<area href="class_agents_1_1_l_s_p_i_1_1_l_s_p_i.html" alt="LSPI" shape="rect" coords="116,112,222,136"/>
<area href="class_agents_1_1_l_s_p_i___s_a_r_s_a_1_1_l_s_p_i___s_a_r_s_a.html" alt="LSPI_SARSA" shape="rect" coords="232,112,338,136"/>
<area href="class_agents_1_1_q___l_e_a_r_n_i_n_g_1_1_q___l_e_a_r_n_i_n_g.html" alt="Q_LEARNING" shape="rect" coords="348,112,454,136"/>
<area href="class_agents_1_1_s_a_r_s_a_1_1_s_a_r_s_a.html" alt="SARSA" shape="rect" coords="464,112,570,136"/>
<area href="class_agents_1_1_policy_evaluation_1_1_policy_evaluation.html" alt="PolicyEvaluation" shape="rect" coords="116,168,222,192"/>
</map>
 </div></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:ac775ee34451fdfa742b318538164070e"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_agents_1_1_agent_1_1_agent.html#ac775ee34451fdfa742b318538164070e">__init__</a></td></tr>
<tr class="memdesc:ac775ee34451fdfa742b318538164070e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Initializes the <code>Agent</code> object.  <a href="#ac775ee34451fdfa742b318538164070e">More...</a><br/></td></tr>
<tr class="separator:ac775ee34451fdfa742b318538164070e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aeb9339921d4a63f47fd93e7d7822f0e1"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aeb9339921d4a63f47fd93e7d7822f0e1"></a>
def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_agents_1_1_agent_1_1_agent.html#aeb9339921d4a63f47fd93e7d7822f0e1">learn</a></td></tr>
<tr class="memdesc:aeb9339921d4a63f47fd93e7d7822f0e1"><td class="mdescLeft">&#160;</td><td class="mdescRight"><b>ABSTRACT</b> <b>METHOD:</b> Defined by child class <br/></td></tr>
<tr class="separator:aeb9339921d4a63f47fd93e7d7822f0e1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a86f3f766914e88f28af9b7ae90740cdf"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_agents_1_1_agent_1_1_agent.html#a86f3f766914e88f28af9b7ae90740cdf">updateAlpha</a></td></tr>
<tr class="memdesc:a86f3f766914e88f28af9b7ae90740cdf"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes a new alpha for the agent based on self.alpha_decay_mode.  <a href="#a86f3f766914e88f28af9b7ae90740cdf">More...</a><br/></td></tr>
<tr class="separator:a86f3f766914e88f28af9b7ae90740cdf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a64fe699622519d8edc3a69716ce076c8"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_agents_1_1_agent_1_1_agent.html#a64fe699622519d8edc3a69716ce076c8">printAll</a></td></tr>
<tr class="memdesc:a64fe699622519d8edc3a69716ce076c8"><td class="mdescLeft">&#160;</td><td class="mdescRight">Prints all of the class information.  <a href="#a64fe699622519d8edc3a69716ce076c8">More...</a><br/></td></tr>
<tr class="separator:a64fe699622519d8edc3a69716ce076c8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a990ff0d3a67632bf9ae1ba5ae51652f5"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_agents_1_1_agent_1_1_agent.html#a990ff0d3a67632bf9ae1ba5ae51652f5">MC_episode</a></td></tr>
<tr class="memdesc:a990ff0d3a67632bf9ae1ba5ae51652f5"><td class="mdescLeft">&#160;</td><td class="mdescRight">Run a single monte-carlo simulation episode from state s with action a following the current policy of the agent.  <a href="#a990ff0d3a67632bf9ae1ba5ae51652f5">More...</a><br/></td></tr>
<tr class="separator:a990ff0d3a67632bf9ae1ba5ae51652f5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae2bac4a51bb0a8329cca4c4c50b4b7b7"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_agents_1_1_agent_1_1_agent.html#ae2bac4a51bb0a8329cca4c4c50b4b7b7">Q_MC</a></td></tr>
<tr class="memdesc:ae2bac4a51bb0a8329cca4c4c50b4b7b7"><td class="mdescLeft">&#160;</td><td class="mdescRight">Use Monte-Carlo samples with the fixed policy to evaluate the Q(s,a).  <a href="#ae2bac4a51bb0a8329cca4c4c50b4b7b7">More...</a><br/></td></tr>
<tr class="separator:ae2bac4a51bb0a8329cca4c4c50b4b7b7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a500a2737f9f41878929da3a807e6e2c0"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_agents_1_1_agent_1_1_agent.html#a500a2737f9f41878929da3a807e6e2c0">evaluate</a></td></tr>
<tr class="memdesc:a500a2737f9f41878929da3a807e6e2c0"><td class="mdescLeft">&#160;</td><td class="mdescRight">Evaluate the current policy for fixed number of samples and store them in samples-by-|S|+2.  <a href="#a500a2737f9f41878929da3a807e6e2c0">More...</a><br/></td></tr>
<tr class="separator:a500a2737f9f41878929da3a807e6e2c0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a119e46064f83e7c5568ee7f687bd0e15"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_agents_1_1_agent_1_1_agent.html#a119e46064f83e7c5568ee7f687bd0e15">episodeTerminated</a></td></tr>
<tr class="memdesc:a119e46064f83e7c5568ee7f687bd0e15"><td class="mdescLeft">&#160;</td><td class="mdescRight">This function adjusts all necessary elements of the agent at the end of the episodes.  <a href="#a119e46064f83e7c5568ee7f687bd0e15">More...</a><br/></td></tr>
<tr class="separator:a119e46064f83e7c5568ee7f687bd0e15"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-attribs"></a>
Public Attributes</h2></td></tr>
<tr class="memitem:a29150be19dd04c7c111b8b986f8f345f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a29150be19dd04c7c111b8b986f8f345f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>initial_alpha</b></td></tr>
<tr class="separator:a29150be19dd04c7c111b8b986f8f345f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a62197192f0fbf4e0675eb37be1c4c175"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a62197192f0fbf4e0675eb37be1c4c175"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>alpha</b></td></tr>
<tr class="separator:a62197192f0fbf4e0675eb37be1c4c175"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5048d52d993b75599b8a2d86eafd4625"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5048d52d993b75599b8a2d86eafd4625"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>alpha_decay_mode</b></td></tr>
<tr class="separator:a5048d52d993b75599b8a2d86eafd4625"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5ced2f75eec62856ab00075cc5313334"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a5ced2f75eec62856ab00075cc5313334"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>boyan_N0</b></td></tr>
<tr class="separator:a5ced2f75eec62856ab00075cc5313334"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a718e5643cd8e89490e113d54313ffb71"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a718e5643cd8e89490e113d54313ffb71"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>candid_alpha</b></td></tr>
<tr class="separator:a718e5643cd8e89490e113d54313ffb71"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3c9212c66ed1dae5e3419645b1ae6f17"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a3c9212c66ed1dae5e3419645b1ae6f17"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>eligibility_trace</b></td></tr>
<tr class="separator:a3c9212c66ed1dae5e3419645b1ae6f17"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae48c0e324c612794831d452b68deefc3"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ae48c0e324c612794831d452b68deefc3"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>eligibility_trace_s</b></td></tr>
<tr class="separator:ae48c0e324c612794831d452b68deefc3"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-static-attribs"></a>
Static Public Attributes</h2></td></tr>
<tr class="memitem:a954b5778d0028f8a45b36d0e8a693216"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a954b5778d0028f8a45b36d0e8a693216"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_agents_1_1_agent_1_1_agent.html#a954b5778d0028f8a45b36d0e8a693216">representation</a> = None</td></tr>
<tr class="memdesc:a954b5778d0028f8a45b36d0e8a693216"><td class="mdescLeft">&#160;</td><td class="mdescRight">The <a class="el" href="class_representations_1_1_representation_1_1_representation.html">Representation</a> to be used by the Agent. <br/></td></tr>
<tr class="separator:a954b5778d0028f8a45b36d0e8a693216"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8a6287602630db6aeffcb6cf5787a216"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8a6287602630db6aeffcb6cf5787a216"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_agents_1_1_agent_1_1_agent.html#a8a6287602630db6aeffcb6cf5787a216">domain</a> = None</td></tr>
<tr class="memdesc:a8a6287602630db6aeffcb6cf5787a216"><td class="mdescLeft">&#160;</td><td class="mdescRight">The <a class="el" href="class_domains_1_1_domain_1_1_domain.html">Domain</a> that the Agent interacts with. <br/></td></tr>
<tr class="separator:a8a6287602630db6aeffcb6cf5787a216"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad986b73e9d5f47a623a9b6d773c25e34"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ad986b73e9d5f47a623a9b6d773c25e34"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_agents_1_1_agent_1_1_agent.html#ad986b73e9d5f47a623a9b6d773c25e34">policy</a> = None</td></tr>
<tr class="memdesc:ad986b73e9d5f47a623a9b6d773c25e34"><td class="mdescLeft">&#160;</td><td class="mdescRight">The <a class="el" href="class_policies_1_1_policy_1_1_policy.html">Policy</a> to be used by the Agent. <br/></td></tr>
<tr class="separator:ad986b73e9d5f47a623a9b6d773c25e34"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1bdff519268fe598008b5bcfac75a538"><td class="memItemLeft" align="right" valign="top">float&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_agents_1_1_agent_1_1_agent.html#a1bdff519268fe598008b5bcfac75a538">initial_alpha</a> = 0.1</td></tr>
<tr class="memdesc:a1bdff519268fe598008b5bcfac75a538"><td class="mdescLeft">&#160;</td><td class="mdescRight">The initial learning rate.  <a href="#a1bdff519268fe598008b5bcfac75a538">More...</a><br/></td></tr>
<tr class="separator:a1bdff519268fe598008b5bcfac75a538"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a98114e5c7c81b3f2003b0a4024bd41f7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a98114e5c7c81b3f2003b0a4024bd41f7"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_agents_1_1_agent_1_1_agent.html#a98114e5c7c81b3f2003b0a4024bd41f7">alpha</a> = 0</td></tr>
<tr class="memdesc:a98114e5c7c81b3f2003b0a4024bd41f7"><td class="mdescLeft">&#160;</td><td class="mdescRight">The learning rate. <br/></td></tr>
<tr class="separator:a98114e5c7c81b3f2003b0a4024bd41f7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6249353116217ff45c96ff345a7c20c5"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_agents_1_1_agent_1_1_agent.html#a6249353116217ff45c96ff345a7c20c5">candid_alpha</a> = 0</td></tr>
<tr class="memdesc:a6249353116217ff45c96ff345a7c20c5"><td class="mdescLeft">&#160;</td><td class="mdescRight">The Candid Learning Rate.  <a href="#a6249353116217ff45c96ff345a7c20c5">More...</a><br/></td></tr>
<tr class="separator:a6249353116217ff45c96ff345a7c20c5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9ac272a92a0586fc45e7b37c5a0fa837"><td class="memItemLeft" align="right" valign="top">list&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_agents_1_1_agent_1_1_agent.html#a9ac272a92a0586fc45e7b37c5a0fa837">eligibility_trace</a> = []</td></tr>
<tr class="memdesc:a9ac272a92a0586fc45e7b37c5a0fa837"><td class="mdescLeft">&#160;</td><td class="mdescRight">The eligibility trace, which marks states as eligible for a learning update.  <a href="#a9ac272a92a0586fc45e7b37c5a0fa837">More...</a><br/></td></tr>
<tr class="separator:a9ac272a92a0586fc45e7b37c5a0fa837"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0b14e488ae28d98d262453f3e9cd6e4d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0b14e488ae28d98d262453f3e9cd6e4d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_agents_1_1_agent_1_1_agent.html#a0b14e488ae28d98d262453f3e9cd6e4d">logger</a> = None</td></tr>
<tr class="memdesc:a0b14e488ae28d98d262453f3e9cd6e4d"><td class="mdescLeft">&#160;</td><td class="mdescRight">A simple object that records the prints in a file. <br/></td></tr>
<tr class="separator:a0b14e488ae28d98d262453f3e9cd6e4d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a04c79cb380ab25ff5e7ce2c996b9e4d9"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a04c79cb380ab25ff5e7ce2c996b9e4d9"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_agents_1_1_agent_1_1_agent.html#a04c79cb380ab25ff5e7ce2c996b9e4d9">episode_count</a> = 0</td></tr>
<tr class="memdesc:a04c79cb380ab25ff5e7ce2c996b9e4d9"><td class="mdescLeft">&#160;</td><td class="mdescRight">Used by some alpha_decay modes. <br/></td></tr>
<tr class="separator:a04c79cb380ab25ff5e7ce2c996b9e4d9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad95eb40b6543f8c24bf81101e8fdb313"><td class="memItemLeft" align="right" valign="top">string&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_agents_1_1_agent_1_1_agent.html#ad95eb40b6543f8c24bf81101e8fdb313">alpha_decay_mode</a> = 'dabney'</td></tr>
<tr class="memdesc:ad95eb40b6543f8c24bf81101e8fdb313"><td class="mdescLeft">&#160;</td><td class="mdescRight">Decay mode of learning rate.  <a href="#ad95eb40b6543f8c24bf81101e8fdb313">More...</a><br/></td></tr>
<tr class="separator:ad95eb40b6543f8c24bf81101e8fdb313"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2fdc7ba9f0128b4a8d011614f8126821"><td class="memItemLeft" align="right" valign="top">list&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_agents_1_1_agent_1_1_agent.html#a2fdc7ba9f0128b4a8d011614f8126821">valid_decay_modes</a> = ['dabney','boyan','const']</td></tr>
<tr class="memdesc:a2fdc7ba9f0128b4a8d011614f8126821"><td class="mdescLeft">&#160;</td><td class="mdescRight">Decay modes with an implementation.  <a href="#a2fdc7ba9f0128b4a8d011614f8126821">More...</a><br/></td></tr>
<tr class="separator:a2fdc7ba9f0128b4a8d011614f8126821"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a125c6abfd41c7c3229c2de3fed0ec960"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a125c6abfd41c7c3229c2de3fed0ec960"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_agents_1_1_agent_1_1_agent.html#a125c6abfd41c7c3229c2de3fed0ec960">boyan_N0</a> = 1000</td></tr>
<tr class="memdesc:a125c6abfd41c7c3229c2de3fed0ec960"><td class="mdescLeft">&#160;</td><td class="mdescRight">The N0 parameter for boyan learning rate decay. <br/></td></tr>
<tr class="separator:a125c6abfd41c7c3229c2de3fed0ec960"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>The <a class="el" href="class_agents_1_1_agent_1_1_agent.html" title="The Agent receives observations from the Domain and performs actions to obtain some goal...">Agent</a> receives observations from the <a class="el" href="class_domains_1_1_domain_1_1_domain.html">Domain</a> and performs actions to obtain some goal. </p>
<p>The Agent interacts with the Domain in discrete timesteps. Each timestep, the Agent receives some observations from the Domain and uses this information to update its <a class="el" href="class_representations_1_1_representation_1_1_representation.html">Representation</a> of the Domain. It then uses its <a class="el" href="class_policies_1_1_policy_1_1_policy.html">Policy</a> to select an action to perform. This process (observe, update, act) repeats itself until some goal or fail state, determined by the Domain, is reached. At this point the <a class="el" href="class_experiments_1_1_experiment_1_1_experiment.html">Experiment</a> determines whether the Agent starts over or has its current policy tested (without any exploration).</p>
<p>The <code>Agent</code> class is a superclass that provides the basic framework for all RL agents. It provides the methods and attributes that allow child classes to interact with the <code>Domain</code>, <code>Representation</code>, <code>Policy</code>, and <code>Experiment</code> classes within the RLPy library. <br/>
 All new agent implementations should inherit from <code>Agent</code>. </p>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a class="anchor" id="ac775ee34451fdfa742b318538164070e"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def __init__ </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>representation</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>policy</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>domain</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>logger</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>initial_alpha</em> = <code>0.1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>alpha_decay_mode</em> = <code>'dabney'</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>boyan_N0</em> = <code>1000</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Initializes the <code>Agent</code> object. </p>
<p>See code <a class="el" href="_agent.html#Agent_init">Here</a>. </p>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a class="anchor" id="a119e46064f83e7c5568ee7f687bd0e15"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def episodeTerminated </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>This function adjusts all necessary elements of the agent at the end of the episodes. </p>
<p>Note: Every agent must call this function at the end of the learning if the transition led to terminal state </p>

</div>
</div>
<a class="anchor" id="a500a2737f9f41878929da3a807e6e2c0"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def evaluate </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>samples</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>MC_samples</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>output_file</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Evaluate the current policy for fixed number of samples and store them in samples-by-|S|+2. </p>
<p>Note: (2 corresponds to action and Q(s,a)) <br/>
 Saves the data generated in a file. <br/>
 See code <a class="el" href="_agent.html#Agent_eval">Here</a>. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">samples</td><td>The number of samples (s,a) </td></tr>
    <tr><td class="paramname">MC_samples</td><td>The number of MC simulations used to estimate Q(s,a) </td></tr>
    <tr><td class="paramname">output_file</td><td>The file in which the data is saved. The number of MC simulations used to estimate Q(s,a) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>DATA The data generated and stored in the output_file </dd></dl>

</div>
</div>
<a class="anchor" id="a990ff0d3a67632bf9ae1ba5ae51652f5"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def MC_episode </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>s</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>a</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tolerance</em> = <code>0</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Run a single monte-carlo simulation episode from state s with action a following the current policy of the agent. </p>
<p>See code <a class="el" href="_agent.html#Agent_MC_episode">Here</a>. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">s</td><td>The state used in the simulation </td></tr>
    <tr><td class="paramname">a</td><td>The action used in the simulation </td></tr>
    <tr><td class="paramname">tolerance</td><td>If the tolerance is set to a non-zero value, episodes will be stopped once the additive value to the sum of rewards drops below this threshold </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>eps_return Sum of rewards </dd>
<dd>
eps_length Length of the Episode </dd>
<dd>
eps_term Specifies the terminal condition of the episode: 0 (stopped due to length), &gt;0 (stopped due to a terminal state) </dd>
<dd>
eps_discounted_return Sum of discounted rewards. </dd></dl>

</div>
</div>
<a class="anchor" id="a64fe699622519d8edc3a69716ce076c8"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def printAll </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Prints all of the class information. </p>
<p>See code <a class="el" href="_agent.html#Agent_printAll">Here</a>. </p>

</div>
</div>
<a class="anchor" id="ae2bac4a51bb0a8329cca4c4c50b4b7b7"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def Q_MC </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>s</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>MC_samples</em> = <code>1000</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tolerance</em> = <code>0</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Use Monte-Carlo samples with the fixed policy to evaluate the Q(s,a). </p>
<p>See code <a class="el" href="_agent.html#Agent_Q_MC">Here</a>. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">s</td><td>The state used in the simulation </td></tr>
    <tr><td class="paramname">a</td><td>The action used in the simulation </td></tr>
    <tr><td class="paramname">tolerance</td><td>If the tolerance is set to a non-zero value, episodes will be stopped once the additive value to the sum of rewards drops below this threshold </td></tr>
    <tr><td class="paramname">MC_samples</td><td>Number of samples to be used to evaluated the Q value </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Q_avg Averaged sum of discounted rewards = estimate of the Q </dd></dl>

</div>
</div>
<a class="anchor" id="a86f3f766914e88f28af9b7ae90740cdf"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def updateAlpha </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>phi_s</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>phi_prime_s</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>eligibility_trace_s</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>gamma</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>nnz</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>terminal</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Computes a new alpha for the agent based on self.alpha_decay_mode. </p>
<p>Note that we divide by number of active features in SARSA. We pass the phi corresponding to the STATE, <em>NOT</em> the copy/pasted phi_s_a. <br/>
 See code <a class="el" href="_agent.html#Agent_updateAlpha">Here</a>. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">nnz</td><td>The number of nonzero features </td></tr>
    <tr><td class="paramname">terminal</td><td>Boolean that determines if the step is terminal or not </td></tr>
    <tr><td class="paramname">phi_s</td><td>The feature vector evaluated at state (s) </td></tr>
    <tr><td class="paramname">phi_prime_s</td><td>The feature vector evaluated at the new state (ns) = (s') </td></tr>
    <tr><td class="paramname">gamma</td><td>The discount factor for learning </td></tr>
    <tr><td class="paramname">eligibility_trace_s</td><td>Eligibility trace using state only (no copy-paste) </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<h2 class="groupheader">Member Data Documentation</h2>
<a class="anchor" id="ad95eb40b6543f8c24bf81101e8fdb313"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">string alpha_decay_mode = 'dabney'</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Decay mode of learning rate. </p>
<p>Options are determined by valid_decay_modes. </p>

</div>
</div>
<a class="anchor" id="a6249353116217ff45c96ff345a7c20c5"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">int candid_alpha = 0</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The Candid Learning Rate. </p>
<p>This value is updated in the updateAlpha method. We use the rate calculated by [Dabney W 2012] <br/>
 <a href="http://people.cs.umass.edu/~wdabney/papers/alphaBounds.p">http://people.cs.umass.edu/~wdabney/papers/alphaBounds.p</a> </p>

</div>
</div>
<a class="anchor" id="a9ac272a92a0586fc45e7b37c5a0fa837"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">list eligibility_trace = []</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The eligibility trace, which marks states as eligible for a learning update. </p>
<p>Used by <a class="el" href="class_agents_1_1_s_a_r_s_a_1_1_s_a_r_s_a.html">SARSA</a> agent when the parameter lambda is set. See: <br/>
 <a href="http://www.incompleteideas.net/sutton/book/7/node1.html">http://www.incompleteideas.net/sutton/book/7/node1.html</a> </p>

</div>
</div>
<a class="anchor" id="a1bdff519268fe598008b5bcfac75a538"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">float initial_alpha = 0.1</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The initial learning rate. </p>
<p>Note that initial_alpha should be set to 1 for automatic learning rate; otherwise, initial_alpha will act as a permanent upper-bound on alpha. </p>

</div>
</div>
<a class="anchor" id="a2fdc7ba9f0128b4a8d011614f8126821"></a>
<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">list valid_decay_modes = ['dabney','boyan','const']</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Decay modes with an implementation. </p>
<p>At the moment the choice is either 'boyan' or 'dabney'. Please use all lowercase letters to properly select a mode. <br/>
 The decay mode 'dabney' is an automatic rate described by Dabney. [Dabney W. 2012] </p>

</div>
</div>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-40370665-1']);
  _gaq.push(['_trackPageview']);
  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.3.1 </li>
  </ul>
</div>
</body>
</html>
